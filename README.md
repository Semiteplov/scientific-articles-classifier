# Scientific Articles Classifier

---

## Постановка задачи

Задача проекта — **многоклассовая классификация научных статей** по их
аннотациям и метаданным.

Используются статьи из **arXiv**, ограниченные доменом:

- Machine Learning,
- Deep Learning,
- Artificial Intelligence.

Каждой статье сопоставляется одна из категорий arXiv (например, `cs.AI`,
`cs.LG`, `stat.ML`).

---

## Данные

Используется
[**arXiv Metadata Dataset**](https://www.kaggle.com/datasets/Cornell-University/arxiv),
содержащий:

- идентификаторы статей,
- названия,
- аннотации,
- авторов,
- категории arXiv.

### Управление данными

- данные версионируются с помощью **DVC**,
- используется **S3-совместимое хранилище (Yandex Object Storage)**,
- сырые и обработанные данные **не хранятся в Git**,
- обработанные данные сохраняются в формате **Parquet**.

---

## Модели

Реализованы три модели классификации текста на базе **PyTorch Lightning**,
модели сделаны для учебных целей, далее будут заменены:

1. **GRU-классификатор** Побайтовое кодирование текста и рекуррентная нейронная
   сеть.

2. **CNN-классификатор** Побайтовые эмбеддинги и несколько сверточных фильтров.

3. **Transformer-классификатор** Encoder-only архитектура с усреднением по
   временной оси.

Все модели используют общий пайплайн кодирования текста и обучаются
единообразно.

---

## Логирование и эксперименты

Для логирования экспериментов используется **MLflow**:

- метрики обучения и валидации,
- гиперпараметры,
- обученные модели.

MLflow сервер предполагается доступным по адресу:

```
http://127.0.0.1:8080
```

---

# Техническая документация

## Setup

### Требования

- Python **>= 3.12**
- `uv`
- Docker
- DVC с поддержкой S3

---

### 1. Клонирование репозитория

```bash
git clone https://github.com/Semiteplov/scientific-articles-classifier.git
cd scientific-articles-classifier
```

---

### 2. Установка зависимостей

Проект использует **uv** для управления окружением. По умолчанию ставится torch
cpu.

```bash
uv sync
```

Для cuda необходимо выполнить следующую команду:

```bash
uv pip install --upgrade torch --index-url https://download.pytorch.org/whl/cu130
```

---

### 3. Установка pre-commit хуков

```bash
uv run pre-commit install
uv run pre-commit run -a
```

Все проверки качества кода должны завершиться без ошибок.

---

### 4. Запуск MLflow (если ранее не был запущен)

```bash
docker compose up -d
```

Интерфейс MLflow будет доступен по адресу:

```
http://127.0.0.1:8080
```

---

### 5. Опционально. Загрузка данных

Данные хранятся в Yandex Object Storage, поэтому необходимо прописать aws keys
для доступа в бакет, для их получения напишите мне в тг, на почту или где-то
ещё. Если не хотите разбираться с ключами, то можете просто скачать данные
[отсюда](https://drive.google.com/file/d/10kTmPqEi6DGpiWnS6GLcI2rU6YgoHPyt/view?usp=sharing)
и положить parquet файл в `data/processed`.

Загрузка встроена в `train.py` и `infer.py`, но можно выполнить отдельно:

```bash
dvc pull data/processed
```

Данные будут загружены из удалённого хранилища.

---

## Обучение моделей (Train)

В проекте используется **Fire** как CLI-роутер и **Hydra** для управления
конфигурациями.

Единая точка входа:

```bash
uv run python main.py
```

---

### Обучение одной модели

Пример для GRU-модели:

```bash
uv run python main.py train --models=gru
```

Доступные модели:

- `gru`
- `cnn`
- `transformer`

---

### Обучение всех моделей

```bash
uv run python main.py train --models=gru,cnn,transformer
```

Hydra выполнит несколько запусков подряд, каждый из которых будет:

- отдельным MLflow run,
- иметь собственные метрики и сохранённую модель.

---

### Этапы обучения

1. Загрузка обработанных данных через DVC (есть возможность загрузить сырые
   данные ~ 5GB и запустить предобработку, **не рекомендуется**).
2. Обучение выбранной модели с использованием PyTorch Lightning.
3. Логирование метрик (loss, accuracy, F1-score) в MLflow.
4. Сохранение модели в MLflow.

---

## Инференс (Infer) - опционально

Инференс реализован как отдельная CLI-команда.

Для инференса требуется `run_id` обученной модели из MLflow.

### Запуск инференса

```bash
uv run python main.py infer \
  --run_id=<MLFLOW_RUN_ID> \
  --texts="This paper proposes a new transformer architecture" \
  --texts="We introduce a novel approach to self-supervised learning"
```

Модель загружается напрямую из MLflow и используется для предсказания класса
статьи.

---

## Управление конфигурацией

Все параметры проекта задаются через **Hydra**.

Структура конфигураций:

```
configs/
├── config.yaml
├── data/
│   └── arxiv.yaml
├── model/
│   ├── gru.yaml
│   ├── cnn.yaml
│   └── transformer.yaml
└── logging/
    └── mlflow.yaml
```

Пример переопределения параметров:

```bash
model.hidden_dim=256 trainer.max_epochs=10
```
