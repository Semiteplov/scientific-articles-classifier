# Scientific Articles Classifier

## Описание проекта

Данный проект является частью дипломной работы на тему:

**«Разработка интеллектуального научного ассистента на основе RAG и
LoRA-адаптеров»**.

Цель дипломной работы — создание интеллектуального ассистента, способного:

- извлекать релевантные научные статьи,
- адаптировать своё поведение под разные научные домены с помощью
  LoRA-адаптеров,
- генерировать ответы на основе извлечённых научных знаний (Retrieval-Augmented
  Generation, RAG).

В рамках этого репозитория реализован **классификатор научных статей**, который
является базовым компонентом будущей системы и используется для:

- маршрутизации запросов к доменным адаптерам,
- фильтрации и структурирования научного корпуса,
- предварительной обработки данных для RAG-пайплайнов.

---

## Постановка задачи

Задача проекта — **многоклассовая классификация научных статей** по их
аннотациям и метаданным.

Используются статьи из **arXiv**, ограниченные доменом:

- Machine Learning,
- Deep Learning,
- Artificial Intelligence.

Каждой статье сопоставляется одна из категорий arXiv (например, `cs.AI`,
`cs.LG`, `stat.ML`).

---

## Данные

Используется
[**arXiv Metadata Dataset**](https://www.kaggle.com/datasets/Cornell-University/arxiv),
содержащий:

- идентификаторы статей,
- названия,
- аннотации,
- авторов,
- категории arXiv.

### Управление данными

- данные версионируются с помощью **DVC**,
- используется **S3-совместимое хранилище (Yandex Object Storage)**,
- сырые и обработанные данные **не хранятся в Git**,
- обработанные данные сохраняются в формате **Parquet**.

---

## Модели

Реализованы три модели классификации текста на базе **PyTorch Lightning**,
модели сделаны для учебных целей, далее будут заменены:

1. **GRU-классификатор** Побайтовое кодирование текста и рекуррентная нейронная
   сеть.

2. **CNN-классификатор** Побайтовые эмбеддинги и несколько сверточных фильтров.

3. **Transformer-классификатор** Encoder-only архитектура с усреднением по
   временной оси.

Все модели используют общий пайплайн кодирования текста и обучаются
единообразно.

---

## Логирование и эксперименты

Для логирования экспериментов используется **MLflow**:

- метрики обучения и валидации,
- гиперпараметры,
- обученные модели.

MLflow сервер предполагается доступным по адресу:

```
http://127.0.0.1:8080
```

---

# Техническая документация

## Setup

### Требования

- Python **>= 3.12**
- `uv`
- Docker
- DVC с поддержкой S3

---

### 1. Клонирование репозитория

```bash
git clone https://github.com/Semiteplov/scientific-articles-classifier.git
cd scientific-articles-classifier
```

---

### 2. Установка зависимостей

Проект использует **uv** для управления окружением.

```bash
uv sync
```

---

### 3. Установка pre-commit хуков

```bash
uv run pre-commit install
uv run pre-commit run -a
```

Все проверки качества кода должны завершиться без ошибок.

---

### 4. Запуск MLflow (если ранее не был запущен)

```bash
docker compose up -d
```

Интерфейс MLflow будет доступен по адресу:

```
http://127.0.0.1:8080
```

---

### 5. Опционально. Загрузка данных

Загрузка встроена в `train.py` и `infer.py`, но можно выполнить отдельно:

```bash
dvc pull data/processed
```

Данные будут загружены из удалённого хранилища.

---

## Обучение моделей (Train)

В проекте используется **Fire** как CLI-роутер и **Hydra** для управления
конфигурациями.

Единая точка входа:

```bash
python -m scientific_articles_classifier.commands
```

---

### Обучение одной модели

Пример для GRU-модели:

```bash
uv run python -m scientific_articles_classifier.commands train model=gru
```

Доступные модели:

- `gru`
- `cnn`
- `transformer`

---

### Обучение всех моделей

```bash
uv run python -m scientific_articles_classifier.commands train -m model=gru,cnn,transformer
```

Hydra выполнит несколько запусков подряд, каждый из которых будет:

- отдельным MLflow run,
- иметь собственные метрики и сохранённую модель.

---

### Этапы обучения

1. Загрузка обработанных данных через DVC (есть возможность загрузить сырые
   данные ~ 5GB и запустить предобработку, **не рекомендуется**).
2. Обучение выбранной модели с использованием PyTorch Lightning.
3. Логирование метрик (loss, accuracy, F1-score) в MLflow.
4. Сохранение модели в MLflow.

---

## Инференс (Infer) - опционально

Инференс реализован как отдельная CLI-команда.

Для инференса требуется `run_id` обученной модели из MLflow.

### Запуск инференса

```bash
uv run python -m scientific_articles_classifier.commands infer \
  --run_id=<mlflow_run_id> \
  --texts="This paper proposes a new transformer architecture"
```

Модель загружается напрямую из MLflow и используется для предсказания класса
статьи.

---

## Управление конфигурацией

Все параметры проекта задаются через **Hydra**.

Структура конфигураций:

```
configs/
├── config.yaml
├── data/
│   └── arxiv.yaml
├── model/
│   ├── gru.yaml
│   ├── cnn.yaml
│   └── transformer.yaml
└── logging/
    └── mlflow.yaml
```

Пример переопределения параметров:

```bash
model.hidden_dim=256 trainer.max_epochs=10
```

---

## Качество кода

Проект соответствует требованиям MLOps:

- отсутствует исполняемый код на уровне модулей,
- данные не коммитятся в Git,
- эксперименты воспроизводимы,
- используется централизованное логирование,
- применяются инструменты линтинга и форматирования (ruff).
